{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2ca7fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the script that compiles the original Best Track Data files from CMA.\n",
    "# Input files: /home/lzhou/Precipitation/TC_Tracks/CMA_Historical_Data/Track_Data/CMABSTdata\n",
    "# Output directory: /home/lzhou/Precipitation/Precipitation_Scripts/Output\n",
    "# Output files: CMA_Best_Tracks.csv, CMA_Best_Tracks.shp and CMA_Best_Tracks_Nodes.shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb53b28d-aeed-4485-8eff-695b61789216",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "\n",
    "from shapely.geometry import LineString, Point, Polygon\n",
    "import geopandas as gpd\n",
    "from pyproj import CRS\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffb97cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#out_dir = '/home/lzhou/Precipitation/Precipitation_Scripts/Output'\n",
    "out_dir = r'D:\\GitHub\\Precipitation_Scripts\\Output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f679a2c-23bf-46b9-9660-0e28149a5895",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#track_folder = '/home/lzhou/Precipitation/TC_Tracks/CMA_Historical_Data/Track_Data/CMABSTdata'\n",
    "track_folder = r'D:\\Precipitation\\CMA_Historical_Data\\Track_Data\\CMABSTdata'\n",
    "files = os.listdir(track_folder)\n",
    "files = [x for x in files if 'txt' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0af4bbbe-3afd-46ea-9e92-85ebab4e07c0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n"
     ]
    }
   ],
   "source": [
    "first_read = 1\n",
    "ar = 0\n",
    "for year in np.arange(1949,2021):\n",
    "    print(year)\n",
    "    filename = 'CH'+str(year)+'BST.txt'\n",
    "    infile = os.path.join(track_folder,filename)\n",
    "    os.path.isfile(infile)\n",
    "\n",
    "    f = open(infile)\n",
    "    content = f.readlines()\n",
    "    f.close()\n",
    "    content = [x.split() for x in content]\n",
    "\n",
    "    fr = 0\n",
    "    while fr < len(content):\n",
    "        #print(content[fr])\n",
    "        ss = content[fr]\n",
    "        nr = int(ss[2])    #number of rows for this track \n",
    "        nsk = fr + 1       #rows that the record starts\n",
    "        \n",
    "        #print('rows to skip, rows to read: ', nsk, nr)\n",
    "    \n",
    "        # read in the track record. \n",
    "        # column unit: Time(UTC), IntensityCategory(Chinese standard), LAT/LON(degree in 0.1),\n",
    "        # PRES(hPa), WND(2-min mean max. sustained wind near the TC center m/s)\n",
    "        try:\n",
    "            dummy = pd.DataFrame(content[nsk:nsk+nr], \\\n",
    "                              columns=['Time','IntensityCategory','LAT','LON','PRES','WND'])\n",
    "        except:\n",
    "            dummy = pd.DataFrame(content[nsk:nsk+nr], \\\n",
    "                              columns=['Time','IntensityCategory','LAT','LON','PRES','WND','OWD'])\n",
    "        \n",
    "        if first_read == 1:\n",
    "            first_read = 0\n",
    "            aa = dummy.copy()\n",
    "        else:\n",
    "            aa = aa.append(dummy,ignore_index=True)\n",
    "            \n",
    "        aa.loc[ar:ar+nr,'IntID'] = ss[1]\n",
    "        aa.loc[ar:ar+nr,'InYearID'] = ss[3]\n",
    "        aa.loc[ar:ar+nr,'CNID'] = ss[4]\n",
    "        aa.loc[ar:ar+nr,'Flag'] = ss[5]            # Flag of the last data line: 0=Decay, 1=Move outside of the region, 2=Merge, 3 = Quais-Stationary\n",
    "        aa.loc[ar:ar+nr,'TimeInterval'] = ss[6]    # Time interval (hour)\n",
    "        aa.loc[ar:ar+nr,'Name'] = ss[7]            # Typhoon Name\n",
    "        aa.loc[ar:ar+nr,'CMAID'] = year*100+int(ss[3])\n",
    "            \n",
    "        ar = ar + nr\n",
    "        fr = fr + nr + 1 \n",
    "\n",
    "# convert data types\n",
    "#aa.IntID = aa.IntID.astype('int')\n",
    "aa.InYearID = aa.InYearID.astype('int')\n",
    "#aa.CNID = aa.CNID.astype('int')\n",
    "aa.Flag = aa.Flag.astype('int')\n",
    "aa.TimeInterval = aa.TimeInterval.astype('int')\n",
    "aa.CMAID = aa.CMAID.astype('int')\n",
    "\n",
    "# correc lat and lon\n",
    "aa.LAT = aa.LAT.astype('float')\n",
    "aa.LON = aa.LON.astype('float')\n",
    "aa.LAT = aa.LAT/10.\n",
    "aa.LON = aa.LON/10.\n",
    "\n",
    "# convert integers to datetime format and get year and month info\n",
    "aa['Time'] = pd.to_datetime(aa['Time'],format='%Y%m%d%H')\n",
    "aa['Year'] = pd.DatetimeIndex(aa['Time']).year\n",
    "aa['Month'] = pd.DatetimeIndex(aa['Time']).month"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b6026c99-ed60-4925-bea0-057ca45fd36e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Old method, will not work when some record has OWD.\n",
    "first_read = 1\n",
    "ar = 0\n",
    "for year in np.arange(1949,2021): \n",
    "    filename = 'CH'+str(year)+'BST.txt'\n",
    "    infile = os.path.join(track_folder,filename)\n",
    "    os.path.isfile(infile)\n",
    "\n",
    "    f = open(infile)\n",
    "    content = f.readlines()\n",
    "    f.close()\n",
    "\n",
    "    fr = 0\n",
    "    #ar = 0\n",
    "    while fr < len(content):\n",
    "        # print(content[fr])\n",
    "        ss = content[fr].split()\n",
    "        nr = int(ss[2])    #number of rows for this track \n",
    "        nsk = fr + 1       #number of rows to skip when read to table\n",
    "        #print('rows to skip, rows to read: ', nsk, nr)\n",
    "    \n",
    "        # read in the track record. \n",
    "        # column unit: Time(UTC), IntensityCategory(Chinese standard), LAT/LON(degree in 0.1),\n",
    "        # PRES(hPa), WND(2-min mean max. sustained wind near the TC center m/s)\n",
    "\n",
    "        if first_read == 1: \n",
    "            aa = pd.read_csv(infile,skiprows=nsk,nrows=nr,sep='\\s+',header=None, \\\n",
    "                             names=['Time','IntensityCategory','LAT','LON','PRES','WND'], \\\n",
    "                             dtype={'Time':'int','IntensityCategory':'int','LAT':'float','LON':'float','PRES':'float','WND':'float'})\n",
    "            first_read = 0\n",
    "        else:\n",
    "            dummy = pd.read_csv(infile,skiprows=nsk,nrows=nr,sep='\\s+',header=None, \\\n",
    "                                names=['Time','IntensityCategory','LAT','LON','PRES','WND'], \\\n",
    "                                dtype={'Time':'int','IntensityCategory':'int','LAT':'float','LON':'float','PRES':'float','WND':'float'})\n",
    "            aa = aa.append(dummy,ignore_index=True)\n",
    "            \n",
    "        aa.loc[ar:ar+nr,'IntID'] = ss[1]\n",
    "        aa.loc[ar:ar+nr,'InYearID'] = ss[3]\n",
    "        aa.loc[ar:ar+nr,'CNID'] = ss[4]\n",
    "        aa.loc[ar:ar+nr,'Flag'] = ss[5]            # Flag of the last data line: 0=Decay, 1=Move outside of the region, 2=Merge, 3 = Quais-Stationary\n",
    "        aa.loc[ar:ar+nr,'TimeInterval'] = ss[6]    # Time interval (hour)\n",
    "        aa.loc[ar:ar+nr,'Name'] = ss[7]            # Typhoon Name\n",
    "        aa.loc[ar:ar+nr,'CMAID'] = year*100+int(ss[3])\n",
    "            \n",
    "        ar = ar + nr\n",
    "        fr = fr + nr + 1 \n",
    "\n",
    "# convert data types\n",
    "#aa.IntID = aa.IntID.astype('int')\n",
    "aa.InYearID = aa.InYearID.astype('int')\n",
    "#aa.CNID = aa.CNID.astype('int')\n",
    "aa.Flag = aa.Flag.astype('int')\n",
    "aa.TimeInterval = aa.TimeInterval.astype('int')\n",
    "aa.CMAID = aa.CMAID.astype('int')\n",
    "\n",
    "# correc lat and lon\n",
    "aa.LAT = aa.LAT/10.\n",
    "aa.LON = aa.LON/10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a10fd29c-cf23-42da-bedb-f4f642d4fa54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cma_tracks = aa.copy()\n",
    "#outfile = os.path.join(out_dir,'CMA_Best_Tracks.csv')\n",
    "#cma_tracks.to_csv(outfile,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c120778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best track csv file\n",
    "#infile = 'CMA_Best_Tracks.csv'\n",
    "#df= pd.read_csv(infile)\n",
    "df = cma_tracks.copy()\n",
    "#df=df[df.Year==2019]\n",
    "\n",
    "# choose initialization projection\n",
    "init_epsg = 4326    # WGS 1984\n",
    "\n",
    "# convert to geopandas dataframe\n",
    "df['geometry'] = df.apply(lambda x: Point((float(x.LON),float(x.LAT))),axis=1)\n",
    "df = gpd.GeoDataFrame(df,geometry='geometry')\n",
    "df.crs = CRS.from_epsg(init_epsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1174b646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect nodes to tracks based on CMAID\n",
    "df2 = df.groupby(['CMAID'])['geometry'].apply(lambda x: LineString(x.tolist()))\n",
    "df2 = gpd.GeoDataFrame(df2,geometry='geometry')\n",
    "\n",
    "# get the information of each track based on CMAID\n",
    "df3 = df[['CMAID','Year','IntID','InYearID','CNID','Flag','Name']].copy()\n",
    "df3 = df3.drop_duplicates()\n",
    "df3.set_index('CMAID',inplace=True)\n",
    "\n",
    "# merge the compiled tracks and tracks' info\n",
    "tracks = df3.merge(df2,left_index=True,right_index=True)\n",
    "tracks = gpd.GeoDataFrame(tracks,geometry='geometry')\n",
    "tracks.crs = CRS.from_epsg(init_epsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39641817",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\zhouluxi\\miniconda3\\envs\\netcdf\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# save to shapefiles\n",
    "tracks_nodes = df.copy()\n",
    "\n",
    "tracks_nodes['Day'] = pd.DatetimeIndex(tracks_nodes['Time']).day\n",
    "tracks_nodes['Hour'] = pd.DatetimeIndex(tracks_nodes['Time']).hour\n",
    "\n",
    "tracks_nodes = tracks_nodes[['Year','Month','Day','Hour','CMAID','InYearID','IntID','CNID','Name', \\\n",
    "                             'Flag','TimeInterval','IntensityCategory','LAT','LON','PRES','WND','OWD','geometry']]\n",
    "\n",
    "outfile1 = os.path.join(out_dir,'CMA_Best_Tracks_Nodes.shp')\n",
    "tracks_nodes.to_file(outfile1)\n",
    "\n",
    "outfile2 = os.path.join(out_dir,'CMA_Best_Tracks.shp')\n",
    "tracks.to_file(outfile2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fa1185",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
